# ğŸ“ KOMPLETAN REZIME - MAÅ INSKO UÄŒENJE (ORI)

## ğŸ“š **Å TA STE SVE NAUÄŒILI:**

---

## ğŸ¯ **1. NADGLEDANO UÄŒENJE (Supervised Learning)**
*UÄimo iz podataka sa unapred definisanim oznakama (X â†’ y)*

### ğŸ·ï¸ **KLASIFIKACIJA** (predviÄ‘amo kategorije)

#### **ğŸ”¢ K-Nearest Neighbors (KNN)**
- **Å ta radi:** PronaÄ‘i K najbliÅ¾ih suseda i glasaj koji je najÄeÅ¡Ä‡i
- **Kada koristiti:** Mali dataset, jednostavan problem
- **Primer:** Prepoznavanje cifara (0-9) iz slika
- **Prednosti:** Jednostavan, radi za male podatke
- **Mane:** Spor za velike podatke, loÅ¡ za visoke dimenzije

```python
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
```

#### **ğŸ§  Naivni Bayes (Naive Bayes)**  
- **Å ta radi:** RaÄuna verovatnoÄ‡e na osnovu Bayesove teoreme
- **Kada koristiti:** Text klasifikacija, spam detekcija
- **Primer:** OdreÄ‘ivanje ko govori reÄenicu (Cartman, Stan, Kyle...)
- **Prednosti:** Brz, dobar za tekst, manje podataka potrebno
- **Mane:** "Naivan" - pretpostavlja nezavisnost features

```python
from sklearn.naive_bayes import MultinomialNB
nb = MultinomialNB()
nb.fit(X_train_bow, y_train)  # BoW = Bag of Words
y_pred = nb.predict(X_test_bow)
```

#### **ğŸŒ Neuronske mreÅ¾e (MLP - Multi-Layer Perceptron)**
- **Å ta radi:** Imitira mozak - slojevi neurona koji uÄe obrasce
- **Kada koristiti:** SloÅ¾eni problemi, veliko podataka
- **Primer:** PredviÄ‘anje zvanja profesora, klasifikacija teksta
- **Prednosti:** Vrlo moÄ‡an, uÄi sloÅ¾ene obrasce
- **Mane:** Zahteva viÅ¡e podataka, sporiji trening

```python
import torch.nn as nn
class MLPClassifier(nn.Module):
    def __init__(self, input_size, hidden_sizes, num_classes):
        # DefiniÅ¡i slojove...
    def forward(self, x):
        # Prosledi podatke kroz slojevi...
```

---

## ğŸ” **2. NENADGLEDANO UÄŒENJE (Unsupervised Learning)**
*TraÅ¾imo skrivene obrasce u podacima BEZ oznaka (samo X, nema y)*

### ğŸ“Š **KLASTEROVANJE** (grupisanje sliÄnih podataka)

#### **â­• K-Means**
- **Å ta radi:** Deli podatke u K grupa (klastera)
- **Kada koristiri:** Eksplorativna analiza, grupisanje kupaca, segmentacija
- **Primer:** Grupisanje cvetova Iris po sliÄnosti
- **Prednosti:** Jednostavan, brz
- **Mane:** Mora unapred znati broj grupa (K), radi samo za sferne oblike

```python
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=3)
kmeans.fit(X)
labels = kmeans.labels_  # kom klasteru pripada svaki element
```

#### **ğŸ¯ DBSCAN**
- **Å ta radi:** GrupiÅ¡e na osnovu gustine, automatski detektuje Å¡um
- **Kada koristiti:** Kada ne znaÅ¡ broj grupa, neregularni oblici klastera
- **Primer:** Detekcija anomalija, grupisanje geografskih podataka
- **Prednosti:** Ne treba unapred K, detektuje Å¡um, bilo koji oblik
- **Mane:** TeÅ¡ko podesiti parametre (eps, min_samples)

```python
from sklearn.cluster import DBSCAN
dbscan = DBSCAN(eps=1.5, min_samples=5)
dbscan.fit(X)
labels = dbscan.labels_  # -1 = Å¡um/outlier
```

---

## ğŸ› ï¸ **3. PREPROCESSING TEHNIKE**

### **ğŸ“Š Za numeriÄke podatke:**
- **StandardScaler:** (vrednost - srednja) / std_devijacija
- **One-hot encoding:** kategorije â†’ binarne kolone
- **Ordinal encoding:** kategorije â†’ brojevi sa redosledom

### **ğŸ“ Za tekst (NLP):**
- **Bag of Words (BoW):** prebroji reÄi u reÄenici
- **CountVectorizer:** automatski BoW sa filtriranjem
- **Stop words:** ukloni Äeste reÄi ("the", "and", "is")

```python
from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(stop_words="english")
X_bow = vectorizer.fit_transform(texts)
```

---

## ğŸ“‹ **4. ZADACI IZ LEKCIJA:**

### **ğŸ”¢ Zadatak 1 (Tvoj kolokvijum):**
- **Problem:** Predvideti zvanje profesora (AsstProf, Prof, AssocProf)
- **Algoritam:** MLP Neuronska mreÅ¾a
- **Features:** NumeriÄki (plata, godine, pol, oblast)
- **Preprocessing:** StandardScaler + One-hot encoding
- **Metrika:** F1-score (87.78%)

### **ğŸ“ Zadatak 2 (Tvoj kolokvijum):**
- **Problem:** Ko govori reÄenicu u South Park-u?
- **Algoritmi:** Naivni Bayes + MLP
- **Features:** Tekst (reÄenice)
- **Preprocessing:** Bag of Words (CountVectorizer)
- **Metrika:** Accuracy (41% NB, 38% MLP)

### **ğŸŒ¸ Iris Classification (iz lekcija):**
- **Problem:** Klasifikacija vrsta cvetova
- **Algoritmi:** KNN, K-Means (klasterovanje)
- **Features:** petal length, petal width, sepal length, sepal width
- **Cilj:** UÄenje osnovnih algoritama

### **ğŸ”¢ Digit Recognition (iz lekcija):**
- **Problem:** Prepoznavanje cifara (0-9) iz slika 8x8 piksela
- **Algoritam:** KNN
- **Features:** 64 piksela (8x8 slike)
- **Cilj:** Primer computer vision-a

### **ğŸ¦ Bank Dataset (zadatak iz lekcije):**
- **Problem:** Eksplorativna analiza bankovnih podataka
- **Algoritam:** K-Means klasterovanje
- **Cilj:** Segmentacija kupaca, otkrivanje grupa

### **ğŸ¨ Image Compression (bonus zadatak):**
- **Problem:** Kompresija slike redukcijom boja
- **Algoritam:** K-Means
- **Cilj:** PraktiÄna primena - od 16M boja â†’ K boja

---

## ğŸ¯ **5. KADA KORISTITI KOJI ALGORITAM:**

### **ğŸ“ˆ Klasifikacija:**
- **KNN:** Mali dataset, jednostavan problem
- **Naivni Bayes:** Tekst, spam detekcija, brza potreba
- **MLP:** SloÅ¾eni problemi, dovoljno podataka, visoka preciznost

### **ğŸ“Š Klasterovanje:**
- **K-Means:** ZnaÅ¡ broj grupa, sferni klasteri, brza analiza
- **DBSCAN:** Ne znaÅ¡ broj grupa, neregularni oblici, detekcija anomalija

### **ğŸ”¤ Tekst:**
- **Bag of Words + Naivni Bayes:** Standardna kombinacija
- **Bag of Words + MLP:** Kad treba veÄ‡a preciznost

---

## ğŸ† **6. METRIKE EVALUACIJE:**

- **Accuracy:** % taÄnih predviÄ‘anja (za balansiraane dataset)
- **F1-score:** Kombinuje precision i recall (za nebalansiraane)
- **Confusion Matrix:** Detaljna analiza greÅ¡aka po klasama

---

## ğŸ’¡ **7. PRAKTIÄŒNI SAVETI:**

### **ğŸ”„ Uvek:**
1. **Podeli podatke:** train_test_split
2. **Preprocess:** fit_transform(train), transform(test)
3. **Treniraj:** model.fit(X_train, y_train)
4. **Evaluiraj:** accuracy_score(y_test, y_pred)

### **âš ï¸ Nikad:**
- Ne fit-uj preprocessing na test podacima
- Ne testiraj na train podacima
- Ne zaboravi random_state za reproducibilnost

---

## ğŸš€ **8. Å TA NISTE PROÅ LI (ali postoji):**

- **Support Vector Machines (SVM)**
- **Random Forest / Decision Trees**
- **Logistic Regression**
- **Deep Learning (CNN, RNN)**
- **Reinforcement Learning**
- **Principal Component Analysis (PCA)**

---

## ğŸ“ **QUICK REFERENCE:**

```python
# OSNOVNI TEMPLATE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# 1. Podeli podatke
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# 2. Preprocess
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)  # fit na train
X_test = scaler.transform(X_test)        # transform na test

# 3. Treniraj model
model.fit(X_train, y_train)

# 4. Evaluiraj
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
```

ğŸ‰ **GOTOV SI ZA KOLOKVIJUM!** ğŸ’ª